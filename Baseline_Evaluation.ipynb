{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a042fc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in ./.arc_env/lib64/python3.12/site-packages (4.4.1)\n",
      "Requirement already satisfied: bert_score in ./.arc_env/lib64/python3.12/site-packages (0.3.13)\n",
      "Requirement already satisfied: transformers in ./.arc_env/lib64/python3.12/site-packages (4.57.3)\n",
      "Requirement already satisfied: torch in ./.arc_env/lib64/python3.12/site-packages (2.9.1)\n",
      "Requirement already satisfied: pandas in ./.arc_env/lib64/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in ./.arc_env/lib64/python3.12/site-packages (2.3.5)\n",
      "Requirement already satisfied: filelock in ./.arc_env/lib64/python3.12/site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in ./.arc_env/lib64/python3.12/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in ./.arc_env/lib64/python3.12/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.arc_env/lib64/python3.12/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in ./.arc_env/lib64/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.arc_env/lib64/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in ./.arc_env/lib64/python3.12/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in ./.arc_env/lib64/python3.12/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec[http]<=2025.10.0,>=2023.1.0 in ./.arc_env/lib64/python3.12/site-packages (from datasets) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in ./.arc_env/lib64/python3.12/site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in ./.arc_env/lib64/python3.12/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.arc_env/lib64/python3.12/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: matplotlib in ./.arc_env/lib64/python3.12/site-packages (from bert_score) (3.10.7)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.arc_env/lib64/python3.12/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.arc_env/lib64/python3.12/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.arc_env/lib64/python3.12/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.arc_env/lib64/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.arc_env/lib64/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.arc_env/lib64/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.arc_env/lib64/python3.12/site-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in ./.arc_env/lib64/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.arc_env/lib64/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.arc_env/lib64/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.arc_env/lib64/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.arc_env/lib64/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.arc_env/lib64/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.arc_env/lib64/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.arc_env/lib64/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.arc_env/lib64/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.arc_env/lib64/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.arc_env/lib64/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.arc_env/lib64/python3.12/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.arc_env/lib64/python3.12/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.arc_env/lib64/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.arc_env/lib64/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.arc_env/lib64/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./.arc_env/lib64/python3.12/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.arc_env/lib64/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.arc_env/lib64/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.arc_env/lib64/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.arc_env/lib64/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in ./.arc_env/lib64/python3.12/site-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: certifi in ./.arc_env/lib64/python3.12/site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in ./.arc_env/lib64/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.arc_env/lib64/python3.12/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./.arc_env/lib64/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.arc_env/lib64/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.arc_env/lib64/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.arc_env/lib64/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.arc_env/lib64/python3.12/site-packages (from requests>=2.32.2->datasets) (2.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.arc_env/lib64/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.arc_env/lib64/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.arc_env/lib64/python3.12/site-packages (from matplotlib->bert_score) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.arc_env/lib64/python3.12/site-packages (from matplotlib->bert_score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.arc_env/lib64/python3.12/site-packages (from matplotlib->bert_score) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.arc_env/lib64/python3.12/site-packages (from matplotlib->bert_score) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in ./.arc_env/lib64/python3.12/site-packages (from matplotlib->bert_score) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.arc_env/lib64/python3.12/site-packages (from matplotlib->bert_score) (3.2.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.arc_env/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.arc_env/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.arc_env/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.arc_env/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.arc_env/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.arc_env/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.arc_env/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n"
     ]
    }
   ],
   "source": [
    "# 1. Install Dependencies\n",
    "!pip install datasets bert_score transformers torch pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f7b608",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tmittal/CSE595/.arc_env/lib64/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from bert_score import score as bertscore_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "DOC_COL = \"document\"\n",
    "REF_COL = \"summary\"\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2369c76a",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "We use the test split of the Multi-News dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e8958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on 50 samples.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"Awesome075/multi_news_parquet\", split=\"test\")\n",
    "# Take a subset of 50 samples for quick evaluation\n",
    "test_dataset = dataset.select(range(100))\n",
    "print(f\"Evaluating on {len(test_dataset)} samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f918b4",
   "metadata": {},
   "source": [
    "## 3. Load Baseline Model\n",
    "We use the generic `facebook/bart-large-cnn` summarization pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d16c51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA A40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check for CUDA availability\n",
    "if torch.cuda.is_available():\n",
    "    device = 0\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = -1\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "try:\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=device)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load on device {device}. Falling back to CPU.\")\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aff9b4",
   "metadata": {},
   "source": [
    "## 4. Generate Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bf52d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating summaries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:07<00:29,  1.34it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "100%|██████████| 50/50 [00:40<00:00,  1.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load tokenizer to ensure proper truncation\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "# Explicitly set max length to silence warnings and ensure correct behavior\n",
    "tokenizer.model_max_length = 1024\n",
    "\n",
    "generated_summaries = []\n",
    "reference_summaries = test_dataset[REF_COL]\n",
    "\n",
    "print(\"Generating summaries...\")\n",
    "for doc in tqdm(test_dataset[DOC_COL]):\n",
    "    try:\n",
    "        # Explicitly tokenize and truncate to 1020 tokens\n",
    "        # We use 1020 instead of 1024 to leave room for special tokens (BOS/EOS) added by the pipeline\n",
    "        inputs = tokenizer(doc, truncation=True, max_length=1020, return_tensors=\"pt\")\n",
    "        \n",
    "        # Decode back to string to pass to pipeline\n",
    "        input_text = tokenizer.decode(inputs[\"input_ids\"][0], skip_special_tokens=True)\n",
    "        \n",
    "        # Pass truncated text to summarizer. Disable truncation here since we handled it manually.\n",
    "        output = summarizer(input_text, max_length=128, min_length=30, do_sample=False, truncation=False)\n",
    "        generated_summaries.append(output[0]['summary_text'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating summary: {e}\")\n",
    "        generated_summaries.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9fe6c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voters in 11 states will pick their governors tonight. Eight of the gubernatorial seats up for grabs are now held by Democrats. Republicans are expected to wrest the North Carolina governorship from Democratic control.\n"
     ]
    }
   ],
   "source": [
    "print(generated_summaries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057e43e0",
   "metadata": {},
   "source": [
    "## 5. Evaluation Metrics\n",
    "We define the exact same metric functions as in `MultiNews.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbacbd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "/home/tmittal/CSE595/.arc_env/lib64/python3.12/site-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def compute_bertscore(cands, refs, model_type=\"roberta-large\", lang=\"en\"):\n",
    "    P, R, F1 = bertscore_score(cands, refs, lang=lang, model_type=model_type)\n",
    "    return np.array([f.item() for f in F1])\n",
    "\n",
    "# Load Bias Classifier\n",
    "bias_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"cirimus/modernbert-large-bias-type-classifier\",\n",
    "    return_all_scores=True,\n",
    "    device=-1,\n",
    ")\n",
    "\n",
    "def compute_neutrality(texts):\n",
    "    # Process in batches to avoid OOM\n",
    "    bias_outputs = bias_classifier(texts, batch_size=8, truncation=True, max_length=1024)\n",
    "    neutrality_scores = []\n",
    "    \n",
    "    for output in bias_outputs:\n",
    "        scores = sorted([float(item[\"score\"]) for item in output], reverse=True)\n",
    "        top3 = scores[:3] if len(scores) >= 3 else scores  # handle fewer categories\n",
    "        avg_top3 = np.mean(top3)\n",
    "        neutrality = (1.0 - avg_top3) ** 2\n",
    "        neutrality_scores.append(neutrality)\n",
    "        \n",
    "    return np.array(neutrality_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693679f6",
   "metadata": {},
   "source": [
    "## 6. Compute Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45345e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing BERTScore...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Compiling the model with `torch.compile` and using a `torch.cpu` device is not supported. Falling back to non-compiled mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean BERTScore F1: 0.8523\n",
      "Computing Neutrality Score...\n",
      "Mean Neutrality Score: 0.4571\n"
     ]
    }
   ],
   "source": [
    "# 1. BERTScore\n",
    "print(\"Computing BERTScore...\")\n",
    "bert_scores = compute_bertscore(generated_summaries, list(reference_summaries))\n",
    "print(f\"Mean BERTScore F1: {bert_scores.mean():.4f}\")\n",
    "\n",
    "# 2. Neutrality Score\n",
    "print(\"Computing Neutrality Score...\")\n",
    "neutrality_scores = compute_neutrality(generated_summaries)\n",
    "print(f\"Mean Neutrality Score: {neutrality_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf60d3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generated Summary</th>\n",
       "      <th>Reference Summary</th>\n",
       "      <th>BERTScore</th>\n",
       "      <th>Neutrality Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Voters in 11 states will pick their governors ...</td>\n",
       "      <td>– It's a race for the governor's mansion in 11...</td>\n",
       "      <td>0.867532</td>\n",
       "      <td>0.441393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A photo of two men kissing was posted on a Fac...</td>\n",
       "      <td>– It turns out Facebook is only guilty of abou...</td>\n",
       "      <td>0.861831</td>\n",
       "      <td>0.354238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Siskiyou County Board of Supervisors voted...</td>\n",
       "      <td>– Not a big fan of Southern California? Neithe...</td>\n",
       "      <td>0.879094</td>\n",
       "      <td>0.251091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Microsoft's acquisition of Nokia is aimed at b...</td>\n",
       "      <td>– Why did Microsoft buy Nokia's phone business...</td>\n",
       "      <td>0.824597</td>\n",
       "      <td>0.950444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Supreme Court's new term kicks off Monday....</td>\n",
       "      <td>– The Supreme Court is facing a docket of high...</td>\n",
       "      <td>0.832153</td>\n",
       "      <td>0.287343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Generated Summary  \\\n",
       "0  Voters in 11 states will pick their governors ...   \n",
       "1  A photo of two men kissing was posted on a Fac...   \n",
       "2  The Siskiyou County Board of Supervisors voted...   \n",
       "3  Microsoft's acquisition of Nokia is aimed at b...   \n",
       "4  The Supreme Court's new term kicks off Monday....   \n",
       "\n",
       "                                   Reference Summary  BERTScore  \\\n",
       "0  – It's a race for the governor's mansion in 11...   0.867532   \n",
       "1  – It turns out Facebook is only guilty of abou...   0.861831   \n",
       "2  – Not a big fan of Southern California? Neithe...   0.879094   \n",
       "3  – Why did Microsoft buy Nokia's phone business...   0.824597   \n",
       "4  – The Supreme Court is facing a docket of high...   0.832153   \n",
       "\n",
       "   Neutrality Score  \n",
       "0          0.441393  \n",
       "1          0.354238  \n",
       "2          0.251091  \n",
       "3          0.950444  \n",
       "4          0.287343  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display Sample Results\n",
    "df_results = pd.DataFrame({\n",
    "    \"Generated Summary\": generated_summaries,\n",
    "    \"Reference Summary\": reference_summaries,\n",
    "    \"BERTScore\": bert_scores,\n",
    "    \"Neutrality Score\": neutrality_scores\n",
    "})\n",
    "\n",
    "display(df_results.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".arc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
